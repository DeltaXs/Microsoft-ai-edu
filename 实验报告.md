# 神经网络简明教程-实践空间站 **实验报告**

## 1  线性回归模型  

> 给定含有1000条记录的数据集`mlm.csv`，其中每条记录均包含两个自变量`x`,`y`和一个因变量`z`，它们之间存在较为明显的线性关系。

**任务：请对数据进行三维可视化分析，并训练出良好的线性回归模型。**  

### **可视化结果**  

![下载.png](https://i.loli.net/2021/01/04/hZ59Ewjmc1odMvT.png)

### **代码&注释**  

read the dataset from file ,then create a (1000,3)list (without x y z in the front)  
读取文件，写成（1000,3）的list （除去文件开头的x y z）  

```python
import numpy as np  
from itertools import islice  
fi = open("Dataset/mlm.csv","r")  
ls = []  
for row in islice(fi, 1, None): 
    e = list(map(float,row.strip("\n").split(",")))  
    ls.append(e)  

#print(ls)
```

use the list to create the input x_matrix and cheak point y_matrix  
用list创建用来输入的x矩阵 和用于检查的y矩阵  

```python
x = np.array(ls).T
x = np.delete(x,2,0)

y = np.array(ls).T
y = np.delete(y,0,0)
y = np.delete(y,0,0)

#print(x)
#print(y.shape)
```  

Draw visual images as required  
按要求绘制可视化图像

```python

X = np.delete(x,0,0)
Y = np.delete(x,1,0)
Z = y

ax = plt.subplot(111,projection='3d') 
ax.scatter(X, Y, Z ,c="b")
plt.show()
```  

Use a linear regression model(a = np.dot(w.T,x) + b)  
使用线性回归模型(a = np.dot(w.T,x) + b)  

Random initialization parameters  
随机初始化参数

```python
w = np.random.randn(2,1)
b = np.random.randn(1,1)

#print(w)
#print(b)
```  

Calculate the estimated value matrix  
计算估计值矩阵

```python
z = np.dot(w.T,x) + b
```

Calculate the parametric gradient  
计算出参数梯度  

(z-y)^2) /2 as the loss function  
[(z-y)^2]/2作为损失函数  

```python
dz = z-y
dw = np.dot(x,dz.T)/ 10000000
db = np.sum( dz , axis=1 ,keepdims=True ) / 10000000
```

Gradient descent  
梯度下降  

```python
w -= dw
b -= db
```  

Do it all over again  
完整的做一次  

```python
z = np.dot(w.T,x) + b

dz = z-y
dw = np.dot(x,dz.T)/ 100000000
db = np.sum( dz , axis=1 ,keepdims=True ) / 100000000

w -= dw
b -= db
```

Do 100,000 cycles  
循环做100,000次

Calculate the percentage error
计算出百分误差

```python
for i in range(100000):
    z = np.dot(w.T,x) + b

    dz = z-y
    
    dw = np.dot(x,dz.T) / 10000000
    db = np.sum( dz , axis=1 ,keepdims=True ) / 1000

    w -= dw
    b -= db
ds = np.sum( abs(dz) , axis=1 ,keepdims=True )
s = np.sum( y , axis=1 ,keepdims=True )
print(100*ds/s)
```

Plug in three test points and see how much the error is  
带入3个测试点看一看误差  

```python
#[[64.32, 6.21, 236.5220491]
#[28.3, 22.62, 30.98357864]
#[19.69, 46.77, -89.8541616]

e = np.mat([[64.32], [6.21]])
print(np.dot(w.T,e) + b - 236.5220491)

e = np.mat([[28.3], [22.62]])
print(np.dot(w.T,e) + b - 30.98357864)

e = np.mat([[19.69], [46.77]])
print(np.dot(w.T,e) + b - -89.8541616)
```

### 完整代码请看[此链接](https://github.com/Dar-Xs/Microsoft-ai-edu/blob/main/linear%20regression.ipynb)（代码语言：Jupyter Notebook）

## 2  非线性多分类器

> 鸢尾花数据集`iris.csv`含有150条记录，每条记录包含萼片长度`sepal length`、萼片宽度`sepal width`、花瓣长度`petal length`和花瓣宽度`petal width`四个数值型特征，以及它的所属类别`class`（可能为`Iris-setosa`,`Iris-versicolor`,`Iris-virginica`三者之一）。  

**任务：请利用该数据集训练出一个良好的非线性分类器。**

### 备注

任务一的数据集由笔者自行模拟随机生成，任务二的Iris数据集来源于UCI Machine Learning Repository。  
